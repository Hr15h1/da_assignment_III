{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377b6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270f6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1504114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83b0a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_count = 0\n",
    "for images, labels in train_loader:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(2,8,i+1)\n",
    "        plt.imshow(images[i].numpy().squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Label: {labels[i].item()}')\n",
    "    plt.show()\n",
    "    images_count += len(images)\n",
    "    if images_count >= 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c3031",
   "metadata": {},
   "source": [
    "Create the autoencoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49acbd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(32, activation='relu') #latent space\n",
    "        ])\n",
    "\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(32, activation='relu', input_shape=(32,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(784, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        latent = self.latent(encoded)\n",
    "        decoded = self.decoder(latent)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d96423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = AutoEncoder()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "outputs_list = []\n",
    "best_model_loss = float('inf')\n",
    "best_model_weights = None\n",
    "\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \", end=\"\")\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(images, training=True)\n",
    "        loss = loss_fn(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "    print(f\"Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, _ in test_loader:\n",
    "            val_images = val_images.view(-1, 28*28).to(device)\n",
    "            val_outputs = model1(val_images, training=False)\n",
    "            val_loss = loss_fn(val_outputs, val_images)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "\n",
    "            val_accuracy = F.mse_loss(val_outputs, val_images)\n",
    "            epoch_val_accuracy += val_accuracy.item()\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / len(test_loader)\n",
    "    avg_val_accuracy = epoch_val_accuracy / len(test_loader)\n",
    "    accuracy_list.append(avg_val_accuracy)\n",
    "\n",
    "    if avg_val_loss < best_model_loss:\n",
    "        best_model_loss = avg_val_loss\n",
    "        best_model_weights = copy.deepcopy(model1.state_dict())\n",
    "        patience_counter = 0\n",
    "    \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation MSE: {avg_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(32, activation='relu') #latent space\n",
    "        ])\n",
    "\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(32, activation='relu', input_shape=(32,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(784, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        latent = self.latent(encoded)\n",
    "        decoded = self.decoder(latent)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = AutoEncoder()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ab8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "outputs_list = []\n",
    "best_model_loss = float('inf')\n",
    "best_model_weights = None\n",
    "\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \", end=\"\")\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(images, training=True)\n",
    "        loss = loss_fn(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "    print(f\"Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, _ in test_loader:\n",
    "            val_images = val_images.view(-1, 28*28).to(device)\n",
    "            val_outputs = model2(val_images, training=False)\n",
    "            val_loss = loss_fn(val_outputs, val_images)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "\n",
    "            val_accuracy = F.mse_loss(val_outputs, val_images)\n",
    "            epoch_val_accuracy += val_accuracy.item()\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / len(test_loader)\n",
    "    avg_val_accuracy = epoch_val_accuracy / len(test_loader)\n",
    "    accuracy_list.append(avg_val_accuracy)\n",
    "\n",
    "    if avg_val_loss < best_model_loss:\n",
    "        best_model_loss = avg_val_loss\n",
    "        best_model_weights = copy.deepcopy(model2.state_dict())\n",
    "        patience_counter = 0\n",
    "    \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation MSE: {avg_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(32, activation='relu') #latent space\n",
    "        ])\n",
    "\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(32, activation='relu', input_shape=(32,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(784, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        latent = self.latent(encoded)\n",
    "        decoded = self.decoder(latent)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b03d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = AutoEncoder()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "outputs_list = []\n",
    "best_model_loss = float('inf')\n",
    "best_model_weights = None\n",
    "\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \", end=\"\")\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model3(images, training=True)\n",
    "        loss = loss_fn(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "    print(f\"Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, _ in test_loader:\n",
    "            val_images = val_images.view(-1, 28*28).to(device)\n",
    "            val_outputs = model3(val_images, training=False)\n",
    "            val_loss = loss_fn(val_outputs, val_images)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "\n",
    "            val_accuracy = F.mse_loss(val_outputs, val_images)\n",
    "            epoch_val_accuracy += val_accuracy.item()\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / len(test_loader)\n",
    "    avg_val_accuracy = epoch_val_accuracy / len(test_loader)\n",
    "    accuracy_list.append(avg_val_accuracy)\n",
    "\n",
    "    if avg_val_loss < best_model_loss:\n",
    "        best_model_loss = avg_val_loss\n",
    "        best_model_weights = copy.deepcopy(model3.state_dict())\n",
    "        patience_counter = 0\n",
    "    \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation MSE: {avg_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(32, activation='relu') #latent space\n",
    "        ])\n",
    "\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(32, activation='relu', input_shape=(32,)),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(784, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        latent = self.latent(encoded)\n",
    "        decoded = self.decoder(latent)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0535534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = AutoEncoder()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf791622",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee7a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "outputs_list = []\n",
    "best_model_loss = float('inf')\n",
    "best_model_weights = None\n",
    "\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \", end=\"\")\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, _ in train_loader:\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model4(images, training=True)\n",
    "        loss = loss_fn(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "    print(f\"Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_images, _ in test_loader:\n",
    "            val_images = val_images.view(-1, 28*28).to(device)\n",
    "            val_outputs = model4(val_images, training=False)\n",
    "            val_loss = loss_fn(val_outputs, val_images)\n",
    "            epoch_val_loss += val_loss.item()\n",
    "\n",
    "            val_accuracy = F.mse_loss(val_outputs, val_images)\n",
    "            epoch_val_accuracy += val_accuracy.item()\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / len(test_loader)\n",
    "    avg_val_accuracy = epoch_val_accuracy / len(test_loader)\n",
    "    accuracy_list.append(avg_val_accuracy)\n",
    "\n",
    "    if avg_val_loss < best_model_loss:\n",
    "        best_model_loss = avg_val_loss\n",
    "        best_model_weights = copy.deepcopy(model4.state_dict())\n",
    "        patience_counter = 0\n",
    "    \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation MSE: {avg_val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
